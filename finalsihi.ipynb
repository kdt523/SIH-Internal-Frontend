{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9322509,"sourceType":"datasetVersion","datasetId":5642718}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom dotenv import load_dotenv\nload_dotenv()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T04:54:19.667257Z","iopub.execute_input":"2024-09-05T04:54:19.667623Z","iopub.status.idle":"2024-09-05T04:54:19.689913Z","shell.execute_reply.started":"2024-09-05T04:54:19.667591Z","shell.execute_reply":"2024-09-05T04:54:19.688995Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"google_api_key=\"AIzaSyAbJPlRhPAmjDtzC48qU9D8oE_r4v4ondU\"","metadata":{"execution":{"iopub.status.busy":"2024-09-05T04:54:19.691602Z","iopub.execute_input":"2024-09-05T04:54:19.692083Z","iopub.status.idle":"2024-09-05T04:54:19.701350Z","shell.execute_reply.started":"2024-09-05T04:54:19.692050Z","shell.execute_reply":"2024-09-05T04:54:19.700429Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if google_api_key == \"\":\n    print(\"API Key not found..!\")\nelse:\n    print(\"Api key found\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T04:54:19.702317Z","iopub.execute_input":"2024-09-05T04:54:19.702622Z","iopub.status.idle":"2024-09-05T04:54:19.713613Z","shell.execute_reply.started":"2024-09-05T04:54:19.702592Z","shell.execute_reply":"2024-09-05T04:54:19.712709Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Api key found\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install llama-index google-generativeai llama-index-llms-gemini pypdf python-dotenv IPython llama-index-embeddings-gemini streamlit llama_index","metadata":{"execution":{"iopub.status.busy":"2024-09-05T04:54:19.715816Z","iopub.execute_input":"2024-09-05T04:54:19.716144Z","iopub.status.idle":"2024-09-05T04:55:02.642483Z","shell.execute_reply.started":"2024-09-05T04:54:19.716085Z","shell.execute_reply":"2024-09-05T04:55:02.641339Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting llama-index\n  Downloading llama_index-0.11.5-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: google-generativeai in /opt/conda/lib/python3.10/site-packages (0.7.2)\nCollecting llama-index-llms-gemini\n  Downloading llama_index_llms_gemini-0.3.4-py3-none-any.whl.metadata (727 bytes)\nRequirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (4.3.1)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\nRequirement already satisfied: IPython in /opt/conda/lib/python3.10/site-packages (8.21.0)\nCollecting llama-index-embeddings-gemini\n  Downloading llama_index_embeddings_gemini-0.2.0-py3-none-any.whl.metadata (704 bytes)\nCollecting streamlit\n  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\nCollecting llama-index-agent-openai<0.4.0,>=0.3.0 (from llama-index)\n  Downloading llama_index_agent_openai-0.3.0-py3-none-any.whl.metadata (728 bytes)\nCollecting llama-index-cli<0.4.0,>=0.3.0 (from llama-index)\n  Downloading llama_index_cli-0.3.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting llama-index-core<0.12.0,>=0.11.5 (from llama-index)\n  Downloading llama_index_core-0.11.5-py3-none-any.whl.metadata (2.4 kB)\nCollecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index)\n  Downloading llama_index_embeddings_openai-0.2.4-py3-none-any.whl.metadata (635 bytes)\nCollecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n  Downloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\nCollecting llama-index-llms-openai<0.3.0,>=0.2.2 (from llama-index)\n  Downloading llama_index_llms_openai-0.2.2-py3-none-any.whl.metadata (705 bytes)\nCollecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n  Downloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl.metadata (728 bytes)\nCollecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\nCollecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\nCollecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index)\n  Downloading llama_index_readers_file-0.2.0-py3-none-any.whl.metadata (5.4 kB)\nCollecting llama-index-readers-llama-parse>=0.3.0 (from llama-index)\n  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\nCollecting nltk>3.8.1 (from llama-index)\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: google-ai-generativelanguage==0.6.6 in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (0.6.6)\nRequirement already satisfied: google-api-core in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.11.1)\nRequirement already satisfied: google-api-python-client in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.141.0)\nRequirement already satisfied: google-auth>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.30.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.8.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.66.4)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.12.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.23.0)\nCollecting google-generativeai\n  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\nCollecting pillow<11.0.0,>=10.2.0 (from llama-index-llms-gemini)\n  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nCollecting google-ai-generativelanguage==0.6.4 (from google-generativeai)\n  Downloading google_ai_generativelanguage-0.6.4-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from IPython) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from IPython) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from IPython) (0.1.7)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from IPython) (3.0.47)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from IPython) (2.18.0)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from IPython) (0.6.2)\nRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from IPython) (5.14.3)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from IPython) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from IPython) (4.9.0)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.4.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.8.2)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: numpy<3,>=1.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<25,>=20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\nRequirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.2.2)\nRequirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (16.1.0)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.32.3)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.1)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.3.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.43)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.4.1)\nCollecting watchdog<5,>=2.1.5 (from streamlit)\n  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\nRequirement already satisfied: narwhals>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.4.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.63.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->IPython) (0.8.4)\nCollecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.0->llama-index)\n  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (6.0.2)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.5->llama-index) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (3.9.5)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (1.2.14)\nCollecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.5->llama-index)\n  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (2024.6.1)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (0.27.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (3.3)\nCollecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.5->llama-index)\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (0.9.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.5->llama-index) (1.16.0)\nCollecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n  Downloading llama_cloud-0.0.15-py3-none-any.whl.metadata (751 bytes)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\nCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\nCollecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index)\n  Downloading llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (2024.5.15)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25,>=20->streamlit) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->IPython) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.21.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (3.0.1)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->IPython) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->IPython) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->IPython) (0.2.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.5->llama-index) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.5->llama-index) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.5->llama-index) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.5->llama-index) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.5->llama-index) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.5->llama-index) (4.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->IPython) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.5)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.62.2)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.48.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.5->llama-index) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.5->llama-index) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.5->llama-index) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.5->llama-index) (0.14.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index) (1.9.0)\nCollecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index)\n  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.5->llama-index) (3.0.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.5->llama-index) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.5->llama-index) (3.21.3)\nDownloading llama_index-0.11.5-py3-none-any.whl (6.8 kB)\nDownloading llama_index_llms_gemini-0.3.4-py3-none-any.whl (5.2 kB)\nDownloading google_generativeai-0.5.4-py3-none-any.whl (150 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_ai_generativelanguage-0.6.4-py3-none-any.whl (679 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.1/679.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading llama_index_embeddings_gemini-0.2.0-py3-none-any.whl (2.9 kB)\nDownloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading llama_index_agent_openai-0.3.0-py3-none-any.whl (13 kB)\nDownloading llama_index_cli-0.3.0-py3-none-any.whl (27 kB)\nDownloading llama_index_core-0.11.5-py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_embeddings_openai-0.2.4-py3-none-any.whl (6.1 kB)\nDownloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl (9.5 kB)\nDownloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_llms_openai-0.2.2-py3-none-any.whl (12 kB)\nDownloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl (5.9 kB)\nDownloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\nDownloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\nDownloading llama_index_readers_file-0.2.0-py3-none-any.whl (38 kB)\nDownloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\nDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\nDownloading llama_cloud-0.0.15-py3-none-any.whl (180 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_parse-0.5.2-py3-none-any.whl (9.5 kB)\nDownloading openai-1.43.0-py3-none-any.whl (365 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\nDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: striprtf, dirtyjson, watchdog, pillow, nltk, jiter, tiktoken, pydeck, openai, llama-cloud, llama-index-legacy, llama-index-core, streamlit, llama-parse, llama-index-readers-file, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, google-ai-generativelanguage, llama-index-readers-llama-parse, google-generativeai, llama-index-llms-gemini, llama-index-embeddings-gemini, llama-index-llms-openai, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index\n  Attempting uninstall: pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: google-ai-generativelanguage\n    Found existing installation: google-ai-generativelanguage 0.6.6\n    Uninstalling google-ai-generativelanguage-0.6.6:\n      Successfully uninstalled google-ai-generativelanguage-0.6.6\n  Attempting uninstall: google-generativeai\n    Found existing installation: google-generativeai 0.7.2\n    Uninstalling google-generativeai-0.7.2:\n      Successfully uninstalled google-generativeai-0.7.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed dirtyjson-1.0.8 google-ai-generativelanguage-0.6.4 google-generativeai-0.5.4 jiter-0.5.0 llama-cloud-0.0.15 llama-index-0.11.5 llama-index-agent-openai-0.3.0 llama-index-cli-0.3.0 llama-index-core-0.11.5 llama-index-embeddings-gemini-0.2.0 llama-index-embeddings-openai-0.2.4 llama-index-indices-managed-llama-cloud-0.3.0 llama-index-legacy-0.9.48.post3 llama-index-llms-gemini-0.3.4 llama-index-llms-openai-0.2.2 llama-index-multi-modal-llms-openai-0.2.0 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.0 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.2 nltk-3.9.1 openai-1.43.0 pillow-10.4.0 pydeck-0.9.1 streamlit-1.38.0 striprtf-0.0.26 tiktoken-0.7.0 watchdog-4.0.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, ServiceContext, StorageContext, load_index_from_storage\nfrom llama_index.llms.gemini import Gemini\nfrom IPython.display import Markdown, display\nimport google.generativeai as genai \nfrom llama_index.embeddings.gemini import GeminiEmbedding\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T04:55:02.643895Z","iopub.execute_input":"2024-09-05T04:55:02.644228Z","iopub.status.idle":"2024-09-05T04:55:06.362758Z","shell.execute_reply.started":"2024-09-05T04:55:02.644190Z","shell.execute_reply":"2024-09-05T04:55:06.361980Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"genai.configure(api_key=google_api_key)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T04:55:06.363818Z","iopub.execute_input":"2024-09-05T04:55:06.364280Z","iopub.status.idle":"2024-09-05T04:55:06.368779Z","shell.execute_reply.started":"2024-09-05T04:55:06.364246Z","shell.execute_reply":"2024-09-05T04:55:06.367811Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for models in genai.list_models():\n    if 'generateContent' in models.supported_generation_methods:\n        print(models.name) ","metadata":{"execution":{"iopub.status.busy":"2024-09-05T04:55:06.370128Z","iopub.execute_input":"2024-09-05T04:55:06.370582Z","iopub.status.idle":"2024-09-05T04:55:07.393292Z","shell.execute_reply.started":"2024-09-05T04:55:06.370538Z","shell.execute_reply":"2024-09-05T04:55:07.392340Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"models/gemini-1.0-pro-latest\nmodels/gemini-1.0-pro\nmodels/gemini-pro\nmodels/gemini-1.0-pro-001\nmodels/gemini-1.0-pro-vision-latest\nmodels/gemini-pro-vision\nmodels/gemini-1.5-pro-latest\nmodels/gemini-1.5-pro-001\nmodels/gemini-1.5-pro\nmodels/gemini-1.5-pro-exp-0801\nmodels/gemini-1.5-pro-exp-0827\nmodels/gemini-1.5-flash-latest\nmodels/gemini-1.5-flash-001\nmodels/gemini-1.5-flash-001-tuning\nmodels/gemini-1.5-flash\nmodels/gemini-1.5-flash-exp-0827\nmodels/gemini-1.5-flash-8b-exp-0827\n","output_type":"stream"}]},{"cell_type":"code","source":"documents = SimpleDirectoryReader(\"/kaggle/input/rag-law\")\ndoc = documents.load_data()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:01:17.601835Z","iopub.execute_input":"2024-09-05T05:01:17.602525Z","iopub.status.idle":"2024-09-05T05:01:58.911454Z","shell.execute_reply.started":"2024-09-05T05:01:17.602485Z","shell.execute_reply":"2024-09-05T05:01:58.910587Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"%pip install llama-index-embeddings-huggingface\n%pip install llama-index-embeddings-instructor","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:02:38.397981Z","iopub.execute_input":"2024-09-05T05:02:38.398374Z","iopub.status.idle":"2024-09-05T05:03:06.872427Z","shell.execute_reply.started":"2024-09-05T05:02:38.398338Z","shell.execute_reply":"2024-09-05T05:03:06.871193Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Collecting llama-index-embeddings-huggingface\n  Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl.metadata (718 bytes)\nRequirement already satisfied: huggingface-hub>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.24.6)\nRequirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (0.11.5)\nCollecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.5)\nCollecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n  Downloading minijinja-2.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.8 kB)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.0.30)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.14)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.8)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.27.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.3)\nRequirement already satisfied: nltk>3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.9.1)\nRequirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.26.4)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (10.4.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.8.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.3.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.9.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.16.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.44.0)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2024.5.15)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.1.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.0.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.19.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.21.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.14.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\nDownloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl (8.6 kB)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading minijinja-2.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (861 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m861.9/861.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: minijinja, sentence-transformers, llama-index-embeddings-huggingface\nSuccessfully installed llama-index-embeddings-huggingface-0.3.1 minijinja-2.2.0 sentence-transformers-3.0.1\nNote: you may need to restart the kernel to use updated packages.\nCollecting llama-index-embeddings-instructor\n  Downloading llama_index_embeddings_instructor-0.2.1-py3-none-any.whl.metadata (759 bytes)\nCollecting instructorembedding<2.0.0,>=1.0.1 (from llama-index-embeddings-instructor)\n  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-instructor) (0.11.5)\nCollecting sentence-transformers<3.0.0,>=2.2.2 (from llama-index-embeddings-instructor)\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: torch<3.0.0,>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-instructor) (2.4.0)\nRequirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (6.0.2)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.9.5)\nRequirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.2.14)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.0.8)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2024.6.1)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.27.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.3)\nRequirement already satisfied: nltk>3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.9.1)\nRequirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.26.4)\nRequirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (10.4.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.8.2)\nRequirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (8.3.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.7.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.12.2)\nRequirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.9.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.16.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (4.44.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (1.14.0)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (1.13.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.1.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.0.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (21.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2024.5.15)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.7.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.20.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.0.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.19.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.21.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (2.1.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (3.5.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (1.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (3.1.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.2.0)\nDownloading llama_index_embeddings_instructor-0.2.1-py3-none-any.whl (3.6 kB)\nDownloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\nDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: instructorembedding, sentence-transformers, llama-index-embeddings-instructor\n  Attempting uninstall: sentence-transformers\n    Found existing installation: sentence-transformers 3.0.1\n    Uninstalling sentence-transformers-3.0.1:\n      Successfully uninstalled sentence-transformers-3.0.1\nSuccessfully installed instructorembedding-1.0.1 llama-index-embeddings-instructor-0.2.1 sentence-transformers-2.7.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n\nsafty_setting = {}\n\nmodel = Gemini(models=\"gemini-pro\", api_key=google_api_key ,    safety_settings={\n        'HATE': 'BLOCK_NONE',\n        'HARASSMENT': 'BLOCK_NONE',\n        'SEXUAL' : 'BLOCK_NONE',\n        'DANGEROUS' : 'BLOCK_NONE'\n    } )\nembed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\",device = \"cuda\" )\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:20:30.972513Z","iopub.execute_input":"2024-09-05T05:20:30.973263Z","iopub.status.idle":"2024-09-05T05:20:33.855638Z","shell.execute_reply.started":"2024-09-05T05:20:30.973221Z","shell.execute_reply":"2024-09-05T05:20:33.854591Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# # from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n# import torch\n\n# # Check if GPU is available\n# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# device","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:03:18.402280Z","iopub.execute_input":"2024-09-05T05:03:18.402792Z","iopub.status.idle":"2024-09-05T05:03:18.406958Z","shell.execute_reply.started":"2024-09-05T05:03:18.402758Z","shell.execute_reply":"2024-09-05T05:03:18.405947Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Configure Service Context\n# service_context = ServiceContext.from_defaults(llm=model, embed_model=gemni_embed_model, chunk_size=800, chunk_overlap=20)\nfrom llama_index.core import Settings\nSettings.llm = model\nSettings.embed_model=embed_model\nSettings.chunk_size=800\nSettings.chunk_overlap=20\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:20:39.372523Z","iopub.execute_input":"2024-09-05T05:20:39.373459Z","iopub.status.idle":"2024-09-05T05:20:39.380129Z","shell.execute_reply.started":"2024-09-05T05:20:39.373414Z","shell.execute_reply":"2024-09-05T05:20:39.379348Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"index = VectorStoreIndex.from_documents(doc)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:03:18.765246Z","iopub.execute_input":"2024-09-05T05:03:18.765564Z","iopub.status.idle":"2024-09-05T05:03:27.613243Z","shell.execute_reply.started":"2024-09-05T05:03:18.765531Z","shell.execute_reply":"2024-09-05T05:03:27.612469Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f38c40d3f72847739d0d79641ea18ee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff4d50792bf5481fb600cfff91bd87b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32963de720af4414ba6f927dcf5e2673"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a64b204b55d4473b03b0d7e8637afbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c25e69917884620852e4b6b5ff23d15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73672bfc6a894acc998f7dfb0c0684dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"592fd25d65bc45a9b8497ca423cf5bdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fffc21a33dc34a789f9dd08189f8a158"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd626d343c04606a1a9b5af5a4ea015"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"748e2290dced4c4a9c42ea5657f0085c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e1c56880885481dab3b03726be552ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd2f37993bf844689ac5e0bf2ddf1b40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a275ec63545b4dd1bc15f4c57139cbe3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa934acdddc84253b0a240fa9d3ff0c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a294513d22ec4c6fb45cdd6556b72791"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a5605fffeef404bbf94297aa0d76321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ab226751ab94bf5a01025219a82b8aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1356852cbbd344a7970b7d934ab733d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62be888418084e368b335f97fdf2fa6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfb82a12f5914c89ae254293db9b0592"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d39457d099b4c57b4f9a65f5f422061"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58916713f9d14c84af8328ebf6aaee55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"099f022ded6643cb8b8690fc488801d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"334a8c70b5bd43e1aca50a5443258b55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93d0b59f1353463a8d9f41cbc2fd658f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9670cf8532bc4ee394039e6e87b738a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"401f7a8e7f554afb83ca5737bd5b0e6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a73af9cfa414a41a6cfd0fa37f58824"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"408dfddf267b49d0bf917f098b8a4536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20a621a717a749c9979a771853787318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5bdcc6ff4aa420381c8b14e1b7c665b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076e02314d1b47d6818afd17ecdbf520"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f0b299e0fcf4db1ad6a902c1808be7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec83e7e84ce488c8d618fa30b66a194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad919129f86d4739b75798ae51353392"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f56bf9e09934240ae26b9cf027c6322"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1ec01ced293469cbd0a9e0821b7ed80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98cd7f04afbe4089922f99596c9bd4fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5553cbac73574f05955b84273231160b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7aad5132be74b0d87ae50ead6422b30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"babaac09b2944ed394e06f8d54b544d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564d721944f14c02951bd0673a30715e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4312936fd7ff4b5fa24cfd2a851edc4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a197232ef63c426e8ef7c16e91627647"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e4d69c4886c431f8e270b1035df04a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a291adf28ebb416895c69971dd415533"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b9c9a79d03c4aae8fde296817d058bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55f091e17fef4e1ea9576d54c3a8fd2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8beb88ee684c9fa7a42f6cfb1d0bea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15d5f5f32522463987d27243dedb2ba7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f52acd7c1b624fb4ae690c32852904c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"051a1845e4444333ae1324bc99d28c98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08230002e08542148a3d847659c78738"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d5c435e2adc42af8e654a571656c55e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9837b55f4734b62897ba46d23a3198d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f38242e77704ca1ab5b250fe79467f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f5cf9931ed946cba336f991c5f28616"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fea48f44bb1d47479a52df27aefeb257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ace731b4dc3b482a8cf17c0548b7f378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ec2577d2334420596f50ff60391b417"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aa57c7edc9b438aad87b033eb4ca1f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c76d85dfb7f04d369eb7eea09e68d211"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"343b3235ce954845aad687b6319be97f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6818cde9ed441ea9db8f1f55e88e319"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"374bd789c73c453e9ea7b96418d04c00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"117f73dad47d48679f9529f2fde7b81d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24229177abf14fb8b9ff162fadbf4243"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10c4bac98f884904808818aca5de9d6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ca7ba9b6c7747649810daa35a59485f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9254a41c2feb4a449c2942511dc5c243"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d64c5e501c5945d9833117581d9b4af5"}},"metadata":{}}]},{"cell_type":"code","source":"index.storage_context.persist()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:03:27.614415Z","iopub.execute_input":"2024-09-05T05:03:27.614779Z","iopub.status.idle":"2024-09-05T05:03:29.988453Z","shell.execute_reply.started":"2024-09-05T05:03:27.614736Z","shell.execute_reply":"2024-09-05T05:03:29.987435Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"query_engine = index.as_query_engine()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:03:29.989775Z","iopub.execute_input":"2024-09-05T05:03:29.990121Z","iopub.status.idle":"2024-09-05T05:03:29.994777Z","shell.execute_reply.started":"2024-09-05T05:03:29.990062Z","shell.execute_reply":"2024-09-05T05:03:29.993831Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from llama_index.core import VectorStoreIndex, get_response_synthesizer\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.query_engine import RetrieverQueryEngine\n\nretriever = VectorIndexRetriever(\n    index=index,\n    similarity_top_k=5,\n)\nquery_engine = RetrieverQueryEngine(\n    retriever=retriever,\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:57.501962Z","iopub.execute_input":"2024-09-05T05:21:57.502652Z","iopub.status.idle":"2024-09-05T05:21:57.508194Z","shell.execute_reply.started":"2024-09-05T05:21:57.502608Z","shell.execute_reply":"2024-09-05T05:21:57.507067Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# retrieved_documents = retriever.retrieve(\"what setion  420 in ipc t and is it bailable or not\")\n\n# if retrieved_documents:\n#     print(\"Retrieved Documents:\")\n#     for i, doc in enumerate(retrieved_documents, 1):\n#         print(f\"\\nDocument {i}:\")\n#         print(doc.text)  # Print the text of the document\n# else:\n#     print(\"No relevant documents found.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:22:00.261788Z","iopub.execute_input":"2024-09-05T05:22:00.262557Z","iopub.status.idle":"2024-09-05T05:22:00.266546Z","shell.execute_reply.started":"2024-09-05T05:22:00.262518Z","shell.execute_reply":"2024-09-05T05:22:00.265634Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"response = query_engine.query(\"what section in ipc for rape or voilence against women tell in detail also tell punisment and also tell me provision for bails in detail to \")\nprint(response.response)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:22:42.201859Z","iopub.execute_input":"2024-09-05T05:22:42.202610Z","iopub.status.idle":"2024-09-05T05:22:46.062335Z","shell.execute_reply.started":"2024-09-05T05:22:42.202569Z","shell.execute_reply":"2024-09-05T05:22:46.061327Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23d8827bed494ab4adca352c451d3388"}},"metadata":{}},{"name":"stdout","text":"The Indian Penal Code (IPC) outlines various offenses related to rape and violence against women, with varying punishments and bail provisions. \n\nHere's a breakdown of some key sections:\n\n* **Section 376:** This section defines rape and outlines the punishment, which can range from rigorous imprisonment for a term which shall not be less than ten years, but which may extend to imprisonment for life, and shall also be liable to fine. \n* **Section 376A:** This section deals with aggravated sexual assault, where the victim suffers grievous bodily harm, maiming, disfigurement, or endangerment of life. The punishment is rigorous imprisonment for a term which shall not be less than twenty years, but which may extend to imprisonment for life, or with death.\n* **Section 376B:** This section addresses sexual intercourse by a husband with his wife during separation without her consent. The punishment is imprisonment of either description for a term which shall not be less than two years but which may extend to seven years, and shall also be liable to fine.\n* **Section 376C:** This section covers sexual intercourse by a person in a position of authority, a public servant, or a superintendent or manager of a jail, remand home, or other place of custody. The punishment is rigorous imprisonment for not less than five years but which may extend to ten years and with fine.\n\nRegarding bail provisions, the Code of Criminal Procedure (CrPC) governs these aspects.  \n\n* **Bail for offenses under Sections 376, 376A, 376B, and 376C:** These offenses are generally considered non-bailable, meaning the accused cannot be released on bail automatically. However, the court can grant bail in exceptional circumstances, considering factors like the nature of the offense, the severity of the crime, the likelihood of the accused absconding, and the possibility of tampering with evidence. \n\nIt's crucial to note that the specific details of bail provisions can vary depending on the individual case and the discretion of the court. \n\n","output_type":"stream"}]},{"cell_type":"code","source":"response = query_engine.query(\"what section for rape in ipc  and tell\")\nprint(response.response)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:05:42.243465Z","iopub.execute_input":"2024-09-05T05:05:42.243869Z","iopub.status.idle":"2024-09-05T05:05:43.892033Z","shell.execute_reply.started":"2024-09-05T05:05:42.243831Z","shell.execute_reply":"2024-09-05T05:05:43.890995Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"211523e24420413690ddc538119cfb7d"}},"metadata":{}},{"name":"stdout","text":"The Indian Penal Code section for rape is 376. \n\n","output_type":"stream"}]},{"cell_type":"code","source":"# %%writefile app3.py\n\n\n# import streamlit as st\n# from llama_index.core import VectorStoreIndex\n# from llama_index.llms.gemini import Gemini\n# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n# import google.generativeai as genai\n# from dotenv import load_dotenv\n# import os\n\n# # Load environment variables\n# load_dotenv()\n\n# google_api_key = \"AIzaSyAbJPlRhPAmjDtzC48qU9D8oE_r4v4ondU\"\n\n# # if google_api_key is None:\n# #     st.error(\"API Key not found..!\")\n# #     st.stop()\n\n# genai.configure(api_key=google_api_key)\n\n# # Initialize models\n# model = Gemini(models=\"gemini-pro\", api_key=google_api_key)\n# embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n\n# # Configure Service Context\n# from llama_index.core import Settings\n# Settings.llm = model\n# Settings.embed_model = embed_model\n# Settings.chunk_size = 800\n# Settings.chunk_overlap = 20\n\n# # Load documents and create index\n# documents = SimpleDirectoryReader(\"/kaggle/input/rag-law\").load_data()\n# index = VectorStoreIndex.from_documents(documents)\n# index.storage_context.persist()\n\n# # Streamlit app\n# st.title(\"Legal Query Chatbot\")\n\n# if 'history' not in st.session_state:\n#     st.session_state.history = []\n\n# def query_engine_response(query):\n#     query_engine = index.as_query_engine()\n#     response = query_engine.query(query)\n#     return response.response\n\n# with st.form(key='query_form', clear_on_submit=True):\n#     query = st.text_input(\"Enter your question:\")\n#     submit_button = st.form_submit_button(\"Submit\")\n\n#     if submit_button and query:\n#         response = query_engine_response(query)\n#         st.session_state.history.append({\"query\": query, \"response\": response})\n#         st.text_area(\"Chat History\", value='\\n'.join([f\"**Q:** {item['query']}\\n**A:** {item['response']}\" for item in st.session_state.history]), height=300)\n\n# if st.session_state.history:\n#     for item in st.session_state.history:\n#         st.write(f\"**Q:** {item['query']}\")\n#         st.write(f\"**A:** {item['response']}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:03:32.094240Z","iopub.execute_input":"2024-09-05T05:03:32.094653Z","iopub.status.idle":"2024-09-05T05:03:32.100739Z","shell.execute_reply.started":"2024-09-05T05:03:32.094606Z","shell.execute_reply":"2024-09-05T05:03:32.099877Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"!curl ipv4.icanhazip.com\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:03:32.101785Z","iopub.execute_input":"2024-09-05T05:03:32.102160Z","iopub.status.idle":"2024-09-05T05:03:33.152143Z","shell.execute_reply.started":"2024-09-05T05:03:32.102117Z","shell.execute_reply":"2024-09-05T05:03:33.151170Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"35.201.141.144\n","output_type":"stream"}]},{"cell_type":"code","source":"!npm install localtunnel","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:03:33.156904Z","iopub.execute_input":"2024-09-05T05:03:33.157240Z","iopub.status.idle":"2024-09-05T05:03:36.553307Z","shell.execute_reply.started":"2024-09-05T05:03:33.157206Z","shell.execute_reply":"2024-09-05T05:03:36.552154Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K\u001b[?25hm##################\u001b[0m] | reify:axios: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://registry.npmjs.o\u001b[0m\u001b[Kpmjs.o\u001b[0m\u001b[K\nadded 22 packages in 2s\n\n3 packages are looking for funding\n  run `npm fund` for details\n\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m New \u001b[33mminor\u001b[39m version of npm available! \u001b[31m10.5.0\u001b[39m -> \u001b[32m10.8.3\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Changelog: \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.8.3\u001b[39m\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Run \u001b[32mnpm install -g npm@10.8.3\u001b[39m to update!\n\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!streamlit run app3.py &>./logs.txt & npx localtunnel --port 8501\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:03:36.554805Z","iopub.execute_input":"2024-09-05T05:03:36.555162Z","iopub.status.idle":"2024-09-05T05:05:41.121566Z","shell.execute_reply.started":"2024-09-05T05:03:36.555125Z","shell.execute_reply":"2024-09-05T05:05:41.120366Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"your url is: https://ninety-wombats-wash.loca.lt\n/kaggle/working/node_modules/localtunnel/bin/lt.js:81\n    throw err;\n    ^\n\nError: connection refused: localtunnel.me:33531 (check your firewall settings)\n    at Socket.<anonymous> \u001b[90m(/kaggle/working/\u001b[39mnode_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11\u001b[90m)\u001b[39m\n\u001b[90m    at Socket.emit (node:events:518:28)\u001b[39m\n\u001b[90m    at emitErrorNT (node:internal/streams/destroy:169:8)\u001b[39m\n\u001b[90m    at emitErrorCloseNT (node:internal/streams/destroy:128:3)\u001b[39m\n\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m\n\nNode.js v20.12.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    'import sys, json; print(\"Execute the next cell and the go to the following URL: \" +json.load(sys.stdin)[\"tunnels\"][0][\"public_url\"])'","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:05:41.123229Z","iopub.execute_input":"2024-09-05T05:05:41.123578Z","iopub.status.idle":"2024-09-05T05:05:42.240564Z","shell.execute_reply.started":"2024-09-05T05:05:41.123541Z","shell.execute_reply":"2024-09-05T05:05:42.239390Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 293, in load\n    return loads(fp.read(),\n  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}